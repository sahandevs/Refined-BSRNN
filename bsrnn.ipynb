{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741a4d6f-e587-4f57-8a1d-1c54412d69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import IPython.display as idp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ee4ca1-ac3e-40d7-845a-23f6c4f625ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e425c21-aa1a-419c-904e-c68e9a683582",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1) Input and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16cbc51-70f7-41c4-be4c-cb6a7c5debd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio\n",
    "\n",
    "sample_rate = 44100 # \n",
    "\n",
    "def show_idp_audio(waveform):\n",
    "    n = 14\n",
    "    return idp.display(idp.Audio(waveform[(3 * n) * sample_rate:(3 * (n + 1)) * sample_rate], rate=sample_rate))\n",
    "\n",
    "def load_audio(path, visualize=False):\n",
    "    waveform, sr = torchaudio.load(path)\n",
    "    # Convert everthing to mono channel for simplicity\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0)\n",
    "        # waveform is now a vector \n",
    "    # Resample everything to 44.1khz for simplicity\n",
    "    resampler = T.Resample(sr, sample_rate, dtype=waveform.dtype)\n",
    "    waveform = resampler(waveform)\n",
    "    \n",
    "    if visualize:\n",
    "        # samplerate = 1/t\n",
    "        # display the first 3 seconds\n",
    "        show_idp_audio(waveform)\n",
    "    \n",
    "    return waveform\n",
    "\n",
    "if visualize:\n",
    "    sample_waveform = load_audio(\"mixture.wav\", visualize=True)\n",
    "\n",
    "    sample_waveform.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45db49d1-7007-4b1f-a9d0-e4a68dfb773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_normalize(waveform, target_rms):\n",
    "    current_rms = torch.sqrt(torch.mean(waveform**2))\n",
    "    gain_factor = target_rms / (current_rms + 1e-10)\n",
    "    normalized_waveform = waveform * gain_factor\n",
    "    return normalized_waveform, gain_factor\n",
    "\n",
    "def rms_denormalize(normalized_waveform, gain_factor):\n",
    "    inverse_gain = 1 / gain_factor\n",
    "    reversed_waveform = normalized_waveform * inverse_gain\n",
    "    return reversed_waveform\n",
    "\n",
    "def peak_normalize(waveform, target_peak):\n",
    "    peak_value = torch.max(torch.abs(waveform))\n",
    "    peak_gain_factor = target_peak / (peak_value + 1e-10)\n",
    "    normalized_waveform = waveform * peak_gain_factor\n",
    "    return normalized_waveform, peak_gain_factor\n",
    "\n",
    "def peak_denormalize(normalized_waveform, peak_gain_factor):\n",
    "    inverse_peak_gain = 1 / peak_gain_factor\n",
    "    reversed_waveform = normalized_waveform * inverse_peak_gain\n",
    "    return reversed_waveform\n",
    "\n",
    "def inspect_waveform(waveform):\n",
    "    transform = T.Loudness(sample_rate)\n",
    "    return f\"LKFS:{transform(waveform.unsqueeze(0))} max: {waveform.max()} min: {waveform.min()} avg: {waveform.mean()}\"\n",
    "\n",
    "def normalize_waveform(waveform, visualize=False):\n",
    "    \"\"\" rms -> peak \"\"\"\n",
    "    # target rms can be anything. the important part here\n",
    "    # is to be constant for all kind of songs\n",
    "\n",
    "    if visualize:\n",
    "        print(\"original: \" + inspect_waveform(waveform))\n",
    "        show_idp_audio(waveform)\n",
    "\n",
    "    normalized_waveform, gain_factor = rms_normalize(waveform, target_rms=0.1)\n",
    "    \n",
    "    if visualize:\n",
    "        print(\"rms_normalize: \" + inspect_waveform(normalized_waveform))\n",
    "        show_idp_audio(normalized_waveform)\n",
    "\n",
    "    # setting target peak to 1.0 forces the values between -1.0 < y < 1.0\n",
    "    normalized_waveform, peak_gain_factor = peak_normalize(normalized_waveform, target_peak=0.1)\n",
    "    \n",
    "    if visualize:\n",
    "        print(\"peak_normalize: \" + inspect_waveform(normalized_waveform))\n",
    "        show_idp_audio(normalized_waveform)\n",
    "    \n",
    "    return normalized_waveform, gain_factor, peak_gain_factor\n",
    "\n",
    "def de_normalize_waveform(waveform, gain_factor, peak_gain_factor, visualize=False):\n",
    "    if visualize:\n",
    "        print(\"de_normalize_waveform: \" + inspect_waveform(waveform))\n",
    "        show_idp_audio(waveform)\n",
    "    \n",
    "    waveform = peak_denormalize(waveform, peak_gain_factor)\n",
    "    \n",
    "    if visualize:\n",
    "        print(\"peak_denormalize: \" + inspect_waveform(waveform))\n",
    "        show_idp_audio(waveform)\n",
    "    waveform = rms_denormalize(waveform, gain_factor)\n",
    "    \n",
    "    if visualize:\n",
    "        print(\"rms_denormalize: \" + inspect_waveform(waveform))\n",
    "        show_idp_audio(waveform)\n",
    "    \n",
    "    return waveform\n",
    "\n",
    "if visualize:\n",
    "    normal_waveform, gain_factor, peak_gain_factor = normalize_waveform(sample_waveform, visualize=True)\n",
    "    _ = de_normalize_waveform(normal_waveform, gain_factor, peak_gain_factor, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7787ec7-063b-47f3-9549-578fc962cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size_in_seconds = 1\n",
    "chunk_size = chunk_size_in_seconds * sample_rate\n",
    "\n",
    "def split(waveform, visualize=False):\n",
    "    # we have a vector by length n and we want to split it to even chunks by length of\n",
    "    # chunk_size\n",
    "    padding_length = (chunk_size - waveform.shape[0] % chunk_size) % chunk_size\n",
    "    waveform = nn.functional.pad(waveform, (0, padding_length), 'constant', 0)\n",
    "    # -1 means automatically infer based on other dims\n",
    "    chunked_waveform = waveform.view(-1, chunk_size)\n",
    "    \n",
    "    if visualize:\n",
    "        fig = plt.figure(constrained_layout=True, figsize=(16, 4))\n",
    "        subfigs = fig.subfigures(2, 1).flat\n",
    "        \n",
    "        # first 3 chunk_size of waveform\n",
    "        w = waveform[:3 * chunk_size].detach().numpy()\n",
    "        ylim = [w.max() * 1.1, w.min() * 1.1]\n",
    "        def time_axis(start, duration):\n",
    "            return torch.arange(start * sample_rate, (duration + start) * sample_rate) / sample_rate\n",
    "        axes = subfigs[0].subplots(1, 1)\n",
    "        axes.plot(time_axis(0, 3), w, linewidth=0.3)\n",
    "        axes.set_xlabel(\"time [s] for first 3 seconds\")\n",
    "        axes.set_ylim(ylim)\n",
    "        \n",
    "        # first 4 chunks + last chunk\n",
    "        axes = subfigs[1].subplots(1, 5)\n",
    "        for i, chunk in enumerate([0, 1, 3, 4, chunked_waveform.shape[0] - 1]): \n",
    "            axes[i].plot(time_axis(0, chunk_size_in_seconds), chunked_waveform[chunk], linewidth=0.3)\n",
    "            axes[i].set_title(f\"chunk {chunk}\")\n",
    "            axes[i].set_ylim(ylim)\n",
    "        \n",
    "    return chunked_waveform, padding_length\n",
    "\n",
    "def merge(chunks, padding_length):\n",
    "    merged_waveform = torch.cat([torch.flatten(x) for x in chunks])\n",
    "    return merged_waveform[:-padding_length]\n",
    "\n",
    "if visualize:\n",
    "    sample_waveform_chunks, padding_length = split(normal_waveform, visualize=True)\n",
    "\n",
    "    assert sample_waveform_chunks.shape[1] == chunk_size\n",
    "\n",
    "    sample_merged = merge(sample_waveform_chunks, padding_length)\n",
    "\n",
    "    assert sample_merged.shape == normal_waveform.shape\n",
    "    assert torch.all(sample_merged == normal_waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d3f9132-958f-4704-8ad9-3a22c4138b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 2048\n",
    "win_length = n_fft\n",
    "hop_length = win_length // 4\n",
    "\n",
    "\n",
    "def visualize_spectogram(chunk, chunk_stft, title='Spectogram'):\n",
    "    import librosa\n",
    "    fig, axis = plt.subplots(2, 1, figsize=(16, 5))\n",
    "    noverlap = win_length - hop_length\n",
    "    axis[0].imshow(librosa.power_to_db(chunk_stft.abs().detach().numpy() ** 2), origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\")\n",
    "    axis[0].set_yscale(\"symlog\")\n",
    "    axis[0].set_title(title)\n",
    "    if chunk is not None:\n",
    "        axis[1].plot(chunk, linewidth=0.5)\n",
    "        axis[1].grid(True)\n",
    "        axis[1].set_xlim([0, len(chunk)])\n",
    "\n",
    "def to_spectogram():\n",
    "    transform_spectogram = T.Spectrogram(n_fft=n_fft, win_length=win_length, hop_length=hop_length,\\\n",
    "                                         window_fn=torch.hamming_window, power=None)\n",
    "    \n",
    "    def inner(chunk, visualize=False, title=''):\n",
    "        chunk_stft = transform_spectogram(chunk)\n",
    "        if visualize:\n",
    "            visualize_spectogram(chunk, chunk_stft, title)\n",
    "\n",
    "        return chunk_stft\n",
    "    return inner\n",
    "\n",
    "if visualize:\n",
    "    print(sample_waveform_chunks[1].shape)\n",
    "    chunk_stft = to_spectogram()(sample_waveform_chunks[1], visualize=True)\n",
    "    chunk_stft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5e3f90-057c-48b1-8340-6b158236836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vis:\n",
    "    def visualize(self, input):\n",
    "        from torchview import draw_graph\n",
    "        y = self(input)\n",
    "        x = draw_graph(self, input_data=input, device='meta', roll=True)\n",
    "        print(f\"--{input.shape}-->f(x)--{y.shape}-->\")\n",
    "        file = x.visual_graph.render(self._get_name())\n",
    "        display(idp.FileLink(\"./\" + file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8adf8d8e-eda8-4354-9256-df3786f80e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers are exctracted from the paper\n",
    "splits_v7 = [\n",
    "   # below 1kh, bandwidth 100hz\n",
    "   (1000, 100),\n",
    "   # above 1kh and below 4khz, bandwidth 250hz\n",
    "   (4000, 250),\n",
    "   (8000, 500),\n",
    "   (16000, 1000),\n",
    "   (20000, 2000),\n",
    "]\n",
    "\n",
    "temporal_dim = int(np.ceil(chunk_size / T.Spectrogram(n_fft=n_fft, win_length=win_length, hop_length=hop_length).hop_length))\n",
    "feature_dim = 128 // 4\n",
    "\n",
    "# Module 1\n",
    "class BandSplit(nn.Module, Vis):\n",
    "    \n",
    "    def __init__(self, splits=splits_v7, fully_connected_out=feature_dim):\n",
    "        super(BandSplit, self).__init__()\n",
    "        \n",
    "        \n",
    "        #### Make splits\n",
    "        # convert fft to freq\n",
    "        freqs = sample_rate * torch.fft.fftfreq(n_fft)[:n_fft // 2 + 1]\n",
    "        freqs[-1] = sample_rate // 2\n",
    "        indices = []\n",
    "        start_freq, start_index = 0, 0\n",
    "        for end_freq, step in splits:\n",
    "            bands = torch.arange(start_freq + step, end_freq + step, step)\n",
    "            start_freq = end_freq\n",
    "            for band in bands:\n",
    "                end_index = freqs[freqs < band].shape[0]\n",
    "                indices.append((start_index, end_index))\n",
    "                start_index = end_index\n",
    "        indices.append((start_index, freqs.shape[0]))\n",
    "        self.band_indices = indices\n",
    "        self.fully_connected_out = fully_connected_out\n",
    "        \n",
    "        self.layer_norms = nn.ModuleList([\n",
    "            # * 2 is for added dim of view_as_real\n",
    "            nn.LayerNorm([(band_end - band_start) * 2, temporal_dim])\n",
    "            for band_start, band_end in self.band_indices\n",
    "        ])\n",
    "        \n",
    "        self.layer_fcs =  nn.ModuleList([\n",
    "            # * 2 is for added dim of view_as_real\n",
    "            nn.Linear((band_end - band_start) * 2, fully_connected_out)\n",
    "            for band_start, band_end in self.band_indices\n",
    "        ])\n",
    "\n",
    "    def forward(self, chunk_ftt):\n",
    "        batch_size = chunk_ftt.size(0)\n",
    "        stack = []\n",
    "        # TODO: can i vectorize this loop?\n",
    "        for i, (band_start, band_end) in enumerate(self.band_indices):\n",
    "            band = chunk_ftt[:, band_start:band_end, :]\n",
    "            # band is shape of (B, F, T)\n",
    "            band = torch.view_as_real(band) # (B, F, T, 2)\n",
    "            # convert to (B, 2, F, T) to be able to feed it to the norm\n",
    "            band = band.permute(0, 3, 1, 2)\n",
    "            \n",
    "            # norm is (..., F, T) and fc is (Fxfully_connected_out)\n",
    "            # we should make norm (..., T, F) in order to feed it to the fc\n",
    "            band = band.reshape(batch_size, -1, band.size(-1)) # -1 = T\n",
    "            norm = self.layer_norms[i](band)\n",
    "            \n",
    "            norm = norm.transpose(-1, -2).contiguous()\n",
    "            fc_y = self.layer_fcs[i](norm)\n",
    "            \n",
    "            stack.append(fc_y)\n",
    "        return torch.stack(stack, dim=1)\n",
    "\n",
    "if visualize:\n",
    "    bandsplit_layer = BandSplit()\n",
    "    bandsplit_y = bandsplit_layer(chunk_stft.unsqueeze(0))\n",
    "    bandsplit_layer.visualize(chunk_stft.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7dfeea-f1c3-41a7-a4ff-06b0f0e39e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 2\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_dim_size = input_dim_size\n",
    "        # paper specified group norm\n",
    "        self.norm = nn.ModuleList([nn.GroupNorm(self.input_dim_size, self.input_dim_size) for _ in range(2)])\n",
    "        self.blstm = nn.ModuleList([nn.LSTM(self.input_dim_size, self.input_dim_size, bidirectional=True, batch_first=True) for _ in range(2)])\n",
    "        self.fc = nn.ModuleList([nn.Linear(self.input_dim_size * 2, self.input_dim_size) for _ in range(2)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input is b, bands(K), temporal_dim(t), input_dim_size\n",
    "        \n",
    "        \n",
    "        # First loops converts the shape to [B, T, K, N]\n",
    "        # and the second loop converts it back to [B, K, T, N]\n",
    "        for i in range(2):\n",
    "            B, K, T, N = x.shape\n",
    "            out = x.view(B * K, T, N)\n",
    "            out = self.norm[i](out.transpose(-1, -2)).transpose(-1, -2)\n",
    "            out = self.blstm[i](out)[0]\n",
    "            out = self.fc[i](out)\n",
    "            x = out.view(B, K, T, N) + x\n",
    "            x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        return x\n",
    "\n",
    "num_blstm_layers=24 // 2\n",
    "\n",
    "class BandSequence(nn.Module, Vis):\n",
    "    \n",
    "    def __init__(self, input_dim_size, num_layers=num_blstm_layers):\n",
    "        super(BandSequence, self).__init__()\n",
    "        self.rnns = nn.Sequential(*[RNN(input_dim_size=input_dim_size) for _ in range(num_layers)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (bands, temporal_dim, fc_out)\n",
    "        return self.rnns(x)\n",
    "\n",
    "if visualize:\n",
    "    bandsequence_layer = BandSequence(input_dim_size=bandsplit_layer.fully_connected_out)\n",
    "    bandsequence_y = bandsequence_layer(bandsplit_y)\n",
    "    bandsequence_layer.visualize(bandsplit_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9fe8f3d-b9ff-4e24-b532-bbbdfd45b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "class MaskEstimation(nn.Module, Vis):\n",
    "    def __init__(self, band_indices, fully_connected_out):\n",
    "        super(MaskEstimation, self).__init__()\n",
    "        \n",
    "        max_indice_diff = max([e - s for s, e in band_indices])\n",
    "        num_hiddens = lambda e, s: 3 * (max_indice_diff - (e - s) + 1)\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.LayerNorm([temporal_dim, fully_connected_out]),\n",
    "                nn.Linear(fully_connected_out, num_hiddens(e, s)),\n",
    "                nn.Tanh(),\n",
    "                # double the output dim to use in GLU\n",
    "                # the extra *2 is for returning as complex\n",
    "                nn.Linear(num_hiddens(e, s), (e - s) * 2 * 2),\n",
    "                nn.GLU()\n",
    "            )\n",
    "            for s, e in band_indices\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (b, k, temporal_dim, fc_out)\n",
    "        parts = []\n",
    "        for i in range(x.shape[1]):\n",
    "            y = self.layers[i](x[:, i]).contiguous()\n",
    "            B, T, F = y.shape\n",
    "            y = y.permute(0, 2, 1).contiguous() # B F T\n",
    "            # basically halve the freq dim and use it for phasee\n",
    "            y = y.view(B, 2, F // 2, T) # (B, 2, F, T)\n",
    "            y = y.permute(0, 2, 3, 1) # (B, F, T, 2)\n",
    "            y = torch.view_as_complex(y.contiguous())\n",
    "            \n",
    "            parts.append(y)\n",
    "        \n",
    "        # (b, f, t)\n",
    "        return torch.cat(parts, dim=-2)\n",
    "\n",
    "    \n",
    "if visualize:   \n",
    "    mask_layer = MaskEstimation(band_indices=bandsplit_layer.band_indices, fully_connected_out=bandsplit_layer.fully_connected_out)\n",
    "    mask_y = mask_layer(bandsequence_y)\n",
    "    mask_layer.visualize(bandsequence_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "848d0886-e194-4a72-8a81-b27554be18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSRNN(nn.Module, Vis):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BSRNN, self).__init__()\n",
    "        \n",
    "        self.split = BandSplit()\n",
    "        self.sequence = BandSequence(input_dim_size=self.split.fully_connected_out)\n",
    "        self.mask = MaskEstimation(band_indices=self.split.band_indices, fully_connected_out=self.split.fully_connected_out)\n",
    "\n",
    "    def forward(self, chunk_fft):\n",
    "        \n",
    "        mean = chunk_fft.mean(dim=(1, 2), keepdim=True)\n",
    "        std = chunk_fft.std(dim=(1, 2), keepdim=True)\n",
    "        chunk_fft = (chunk_fft - mean) / (std + 1e-5)\n",
    "        \n",
    "        y = self.split(chunk_fft)\n",
    "        y = self.sequence(y)\n",
    "        mask = self.mask(y)\n",
    "        \n",
    "        mask = mask * std + mean\n",
    "\n",
    "        return mask\n",
    "\n",
    "if visualize:\n",
    "    bsrnn = BSRNN().cuda()\n",
    "    bsrnn_y = bsrnn(chunk_stft.unsqueeze(0).cuda())\n",
    "    bsrnn.visualize(chunk_stft.unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ac4f830-f48c-4900-903b-593ab23c4bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def from_spectogram():\n",
    "    # We are using GriffinLim to ensure the output size\n",
    "    transform_inv_spectogram = T.InverseSpectrogram(n_fft=n_fft, win_length=win_length, hop_length=hop_length,\\\n",
    "                                                    window_fn=torch.hamming_window)\n",
    "\n",
    "    def inner(chunk_stft, visualize=False):\n",
    "        chunk = transform_inv_spectogram(chunk_stft)\n",
    "    \n",
    "        if visualize:\n",
    "            visualize_spectogram(chunk.detach().numpy(), chunk_stft)\n",
    "\n",
    "        return chunk\n",
    "    return inner\n",
    "\n",
    "if visualize:\n",
    "    print(bsrnn_y.shape)\n",
    "    masked_complex = chunk_stft * bsrnn_y[0].cpu()\n",
    "\n",
    "    chunk_y = from_spectogram()(masked_complex, visualize=True)\n",
    "    chunk_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf3b1032-7bc6-40f9-9745-854c3be034b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize:\n",
    "    chunk_x = de_normalize_waveform(sample_waveform_chunks[1], gain_factor, peak_gain_factor)\n",
    "    chunk_y = de_normalize_waveform(chunk_y, gain_factor, peak_gain_factor)\n",
    "\n",
    "    print(\"In:\")\n",
    "    show_idp_audio(chunk_x)\n",
    "    print(\"Out:\")\n",
    "    show_idp_audio(chunk_y.detach().numpy())\n",
    "    print(chunk_y.shape)\n",
    "    chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05ed9801-0fde-4110-a40f-95b20d787857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b72ccde-384a-40da-b144-1206e527d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put Everything Together! audio in, audio out!\n",
    "\n",
    "\n",
    "class MSSBandSplitRNN(nn.Module, Vis):\n",
    "    def __init__(self):\n",
    "        super(MSSBandSplitRNN, self).__init__()\n",
    "        self.to_spectogram = to_spectogram()\n",
    "        self.from_spectogram = from_spectogram()\n",
    "        self.bsrnn = BSRNN()\n",
    "        \n",
    "    def forward(self, waveform):\n",
    "        \"\"\" Waveform in -> Waveform out :) \"\"\"\n",
    "        \n",
    "        # 1) normalize\n",
    "        # 2) split\n",
    "        # 3) feed to bsrnn\n",
    "        # 4) convert spectogram to audio\n",
    "        # 5) merge all splits\n",
    "        # 6) de-normalize\n",
    "        \n",
    "        normal_waveform, gain_factor, peak_gain_factor = normalize_waveform(waveform)\n",
    "        splits, padding_length = split(normal_waveform)\n",
    "        masked_splits = [() for _ in range(len(splits))]\n",
    "        for i, x_split in enumerate(splits):\n",
    "            split_stft = self.to_spectogram(x_split)\n",
    "            mask = self.bsrnn(split_stft.unsqueeze(0))[0]\n",
    "            \n",
    "            masked_complex = mask\n",
    "            \n",
    "            wave = self.from_spectogram(masked_complex)\n",
    "            masked_splits[i] = wave\n",
    "        \n",
    "        masked_waveform = merge(masked_splits, padding_length)\n",
    "        y = de_normalize_waveform(masked_waveform, gain_factor, peak_gain_factor)\n",
    "        return y\n",
    "\n",
    "if visualize:\n",
    "    torch.set_default_device('cuda')\n",
    "    with torch.no_grad():\n",
    "        model = MSSBandSplitRNN()\n",
    "        y = model(sample_waveform.cuda())\n",
    "\n",
    "\n",
    "    print(\"In:\")\n",
    "    show_idp_audio(sample_waveform)\n",
    "    print(\"Out:\")\n",
    "    show_idp_audio(y.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b004c354-c93f-4d13-a326-3197b0b8a38f",
   "metadata": {},
   "source": [
    "# 2) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75190bcb-729e-4b92-ba27-f8b71421137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.mae_stft_real = nn.L1Loss()\n",
    "        self.mae_stft_imag = nn.L1Loss()\n",
    "        self.mae_inv_stft  = nn.L1Loss()\n",
    "    \n",
    "    def forward(self, pred_stft, target_stft,  pred_inv_stft, target_inv_stft):\n",
    "        loss_r = self.mae_stft_real(pred_stft.real, target_stft.real)\n",
    "        loss_i = self.mae_stft_imag(pred_stft.imag, target_stft.imag)\n",
    "        loss_t = self.mae_inv_stft(pred_inv_stft, target_inv_stft)\n",
    "        loss = loss_r + loss_i + loss_t\n",
    "        return loss\n",
    "\n",
    "def compute_usdr(pred, target, delta = 1e-7):\n",
    "    if pred.shape[0] < target.shape[0]:\n",
    "        padding = target.shape[0] - pred.shape[0]\n",
    "        pred = torch.nn.functional.pad(pred, (0, padding), \"constant\", 0)\n",
    "    num = torch.sum(torch.square(target))\n",
    "    den = torch.sum(torch.square(target - pred))\n",
    "    num += delta\n",
    "    den += delta\n",
    "    usdr = 10 * torch.log10(num / den)\n",
    "    return usdr.mean()\n",
    "\n",
    "if visualize:\n",
    "    torch.set_default_device('cpu')\n",
    "    target_wf = load_audio(\"drums.wav\")\n",
    "    normal_target_wf, gain_factor, peak_gain_factor = normalize_waveform(target_wf)\n",
    "    target_wf_chunks, padding_length = split(normal_target_wf)\n",
    "    stft = to_spectogram()\n",
    "    inv_stft = from_spectogram()\n",
    "    print(\"target:\")\n",
    "    show_idp_audio(target_wf_chunks[1])\n",
    "    target_stft = stft(target_wf_chunks[1], visualize=True, title=\"Target\")\n",
    "    print(\"input:\")\n",
    "    show_idp_audio(sample_waveform_chunks[1])\n",
    "    sample_stft = stft(sample_waveform_chunks[1], visualize=True, title=\"Input\")\n",
    "\n",
    "    # x * mask = target_stft / x\n",
    "    # f(x) = stft - \n",
    "\n",
    "    mask_stft = target_stft / sample_stft\n",
    "    visualize_spectogram(inv_stft(mask_stft), mask_stft, title=\"Mask stft\")\n",
    "    print(\"Mask:\")\n",
    "    show_idp_audio(inv_stft(mask_stft))\n",
    "    target_y = sample_stft * mask_stft\n",
    "    print(\"Target_y: \")\n",
    "    show_idp_audio(inv_stft(target_y))\n",
    "    visualize_spectogram(inv_stft(target_y), target_y, title=\"Target_y stft calc\")\n",
    "\n",
    "\n",
    "    loss_fn = CustomLoss()\n",
    "    loss = loss_fn.forward(target_y, target_stft, inv_stft(target_y), inv_stft(target_stft))\n",
    "    print(f\"loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e72fc97f-3d1c-4faa-8f6f-ec06f611d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Dataloader\n",
    "\n",
    "torch.set_default_device('cpu')\n",
    "\n",
    "class Dataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, dir_=\"/home/sahand/BandSplit-RNN/musdb18hq/\", validation=False):\n",
    "        super(Dataset, self).__init__()\n",
    "        path = dir_ + (\"test\" if validation else \"train\")\n",
    "        print(path)\n",
    "        self.files = [entry for entry in os.scandir(path) if entry.is_dir()]\n",
    "        random.shuffle(self.files)\n",
    "    \n",
    "    def iterator(self):\n",
    "        torch.set_default_device('cpu')\n",
    "        to_stft = to_spectogram()\n",
    "        for i in range(self.start_index, self.end_index):\n",
    "            d = self.files[i]\n",
    "            mixture = f\"{d.path}/mixture.wav\"\n",
    "            target = f\"{d.path}/drums.wav\"\n",
    "\n",
    "            normal_mix, _, _ = normalize_waveform(load_audio(mixture))\n",
    "            normal_target, _, _ = normalize_waveform(load_audio(target))\n",
    "\n",
    "            normal_mix, _ = split(normal_mix)\n",
    "            normal_target, _ = split(normal_target)\n",
    "\n",
    "            for mix, target in zip(normal_mix, normal_target):\n",
    "                mix_stft = to_stft(mix)\n",
    "                target_stft = to_stft(target)\n",
    "                # Accumulate STFTs in the batch\n",
    "                yield (mix_stft, target_stft)\n",
    "\n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        if worker_info is not None:\n",
    "            total_files = len(self.files)\n",
    "            per_worker = int(math.ceil(total_files / float(worker_info.num_workers)))\n",
    "            self.start_index = worker_info.id * per_worker\n",
    "            self.end_index = min(self.start_index + per_worker, total_files)\n",
    "        else:\n",
    "            self.start_index = 0\n",
    "            self.end_index = len(self.files)\n",
    "\n",
    "        return iter(self.iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a75952a2-8af0-465a-8db3-9259e55768cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bcf93d8-3df8-4651-8d0f-23a4d9294ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sahand/BandSplit-RNN/musdb18hq/train\n",
      "/home/sahand/BandSplit-RNN/musdb18hq/test\n"
     ]
    }
   ],
   "source": [
    "batch_size=95\n",
    "clip_grad_norm=5\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(Dataset(validation=False), num_workers=1, \n",
    "                                          batch_size=batch_size, drop_last=True,\n",
    "                                          prefetch_factor=4,\n",
    "                                          persistent_workers=True)\n",
    "val_loader   = torch.utils.data.DataLoader(Dataset(validation=True), num_workers=1, \n",
    "                                          batch_size=batch_size, drop_last=True,\n",
    "                                          prefetch_factor=4,\n",
    "                                          persistent_workers=True)\n",
    "\n",
    "\n",
    "# model = BSRNN()\n",
    "model = torch.load(\"./drums-reversed-mask/bsrnn-102-0.031533900648355484.pt\")\n",
    "import datetime\n",
    "\n",
    "name = f\"baseline\"\n",
    "prefix=f\"./train-logs/{name}-{datetime.datetime.now()}\"\n",
    "if not os.path.exists(name):\n",
    "    os.makedirs(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3db422f6-b9d6-4755-9fb1-3e1eff52ced3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 14:05:22.776964: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-21 14:05:22.777003: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-21 14:05:22.777596: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-21 14:05:22.781271: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-21 14:05:23.298318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/sahand/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/contrib/handlers/tqdm_logger.py:126: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cac9f8c82a542e88785d1e5cad5c06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ec4e2b2fee4f0592fa14da22dfb417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfaf059104064fa9befad2ce7da2832a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b09502969c4a37bc0b6fe52c899535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3873127e51974f32a5d1131e25ea5e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee50e976c9ad47c0912dfda46cac4f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542316d97e2f45ce87cf9857f004f44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f734e4011545f390b8dfa4ee2f0055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b067a4f4d3d1464ea9173d3f87d133a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c737c264ebda46099cbfaf2386f5e070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497bef02c7df4abf91a804fd785f54de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5305708fad154ef6ae76579575e4b92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fe8b0000614c58b89542558f577c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916858eae4f04f929192efd10cdeb783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edafbac16f245aeaa4b199c865dc199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080956d1542d4caab53a03720806c7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa16f838e9d4fd9bf145d246cb7e1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7234ca61b0b64e8c8e12fd3e34a90245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df586c83549944efb7441d1874ba31f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fa38a3b4d046b6aee58afb173f87f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4378fd8bd46942d5991671babc3e9267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ff671b061547cda64d5baa114ef810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7897860c4546c6a55b53def0f93330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffb3ba920af492e82c4ef9e676d3f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25301a3b22942e2aeb73809c68d7611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09af5a9956224bf0ba310cf5fa507d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659c6ad7689f479b9ed998c974a96ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d336c4b718304cc6a1e8178c3af38891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939d217e71bc462a80b366036d030374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63dccde5f104a0486e91cbefdf19184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40624d8bf47b45b5b852a7101473b2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e33ce48a4634b9b87bfa44f74571054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cc86a52530401c9f4a77019a24b597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0702710ec14f4dac3947b438597168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef13dd2ae294e0b83a8805ba179708e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734def289d59488aa585b9795d4a75de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973b1c75ccce4ebc8684ec33416a891e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805628e04f2d4c7e899e6e96b450a43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33980378603747fbabf500b5679ebd88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5992133ada6436caf224796e00970ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b869a56c6f294500a420fc675a40cbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8c7f3cb5d8459c92cdf63c260aa5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c720c433bfc4803b94dff186d48ed61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302d14a7162e4c34ab279007c6ea26b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cef143baa8e4bfebd960e4f8cd3e6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3dd757bce64eb7a75ee39c485aafed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b3f94278614268ad90689bd8ecf031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89f77f8801c40aabdaccce8680bd3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65072a238cb54641a3a1985db1f25d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee79f864d29941bc8ad530f4aa0b7e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854bdaa9268345769ae9dc61cd7e6439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87561e55ed0475ab46505311f91ab06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a25ff410fb448caaa2b8b34aca6b14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787550e3a4dc41ba84f6aec366a982a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24f75114248495c824016b3e4392116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f950c268f949338d8e6306d648b0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f8d58d33c84da0a255bc636faf8a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179b5327d40f4705981d9ef4c73d723c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2529fd036feb436da7e9b9fd87d82783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab1e83ed36d4aa1bfd8ed154a3f881b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f8ea4ee905499e868e409e6aa0f0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/241]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 96\u001b[0m\n\u001b[1;32m     93\u001b[0m pbar\u001b[38;5;241m.\u001b[39mattach(trainer, metric_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrunning_avg_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrunning_avg_usdr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Run Training\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/engine/engine.py:898\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/engine/engine.py:941\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 941\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/engine/engine.py:999\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 999\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/engine/engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/engine/engine.py:965\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 965\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    967\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/ignite/engine/engine.py:1074\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "Cell \u001b[0;32mIn[20], line 27\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     26\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip_grad_norm)\n\u001b[0;32m---> 27\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m usdr_value \u001b[38;5;241m=\u001b[39m compute_usdr(inv_y_mask, inv_mask_stft)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124musdr\u001b[39m\u001b[38;5;124m'\u001b[39m: usdr_value}\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/torch/optim/adam.py:551\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    549\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt)\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 551\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps]\n\u001b[1;32m    552\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps]\n\u001b[1;32m    554\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m _stack_if_compiling([(lr \u001b[38;5;241m/\u001b[39m bc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/torch/optim/adam.py:551\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    549\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt)\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 551\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps]\n\u001b[1;32m    552\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps]\n\u001b[1;32m    554\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m _stack_if_compiling([(lr \u001b[38;5;241m/\u001b[39m bc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_get_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/bsrnn/lib/python3.10/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "from ignite.handlers import ModelCheckpoint, Checkpoint, DiskSaver, global_step_from_engine\n",
    "from ignite.contrib.handlers import TensorboardLogger, global_step_from_engine, ProgressBar, TensorboardLogger\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = CustomLoss()\n",
    "\n",
    "torch.set_default_device('cuda')\n",
    "inv_stft_gpu = from_spectogram()\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    mix_stft, mask_stft = batch\n",
    "    mix_stft, mask_stft = mix_stft.to('cuda'), mask_stft.to('cuda')\n",
    "    y_mask = model(mix_stft)\n",
    "    inv_y_mask = inv_stft_gpu(y_mask)\n",
    "    inv_mask_stft = inv_stft_gpu(mask_stft)\n",
    "    loss = loss_fn(y_mask, mask_stft, inv_y_mask, inv_mask_stft)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "    optimizer.step()\n",
    "    \n",
    "    usdr_value = compute_usdr(inv_y_mask, inv_mask_stft).item()\n",
    "    return {'loss': loss.item(), 'usdr': usdr_value}\n",
    "\n",
    "# Evaluation Step\n",
    "# def evaluate_step(engine, batch):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         mix_stft, mask_stft = batch\n",
    "#         mix_stft, mask_stft = mix_stft.to('cuda'), mask_stft.to('cuda')\n",
    "#         y_mask = model(mix_stft)\n",
    "#         inv_y_mask = inv_stft_gpu(y_mask)\n",
    "#         inv_mask_stft = inv_stft_gpu(mask_stft)\n",
    "#         return y_mask, mask_stft, inv_y_mask, inv_mask_stft\n",
    "\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "# evaluator = Engine(evaluate_step)\n",
    "\n",
    "running_avg_usdr = RunningAverage(output_transform=lambda x: x['usdr'])\n",
    "running_avg_usdr.attach(trainer, 'running_avg_usdr')\n",
    "running_avg_loss = RunningAverage(output_transform=lambda x: x['loss'])\n",
    "running_avg_loss.attach(trainer, 'running_avg_loss')\n",
    "\n",
    "tb_logger = TensorboardLogger(log_dir=f\"{prefix}/tb\")\n",
    "tb_logger.attach_output_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_COMPLETED,\n",
    "    tag=\"training\",\n",
    "    output_transform=lambda x: {\"running_avg_loss\": trainer.state.metrics['running_avg_loss'], \n",
    "                                \"running_avg_usdr\": trainer.state.metrics['running_avg_usdr']}\n",
    ")\n",
    "\n",
    "\n",
    "# Model Checkpointing\n",
    "to_save = {\n",
    "    'trainer': trainer,\n",
    "    'model': model,\n",
    "    'optimizer': optimizer,\n",
    "    'running_avg_usdr': running_avg_usdr,\n",
    "    'running_avg_loss': running_avg_loss\n",
    "}\n",
    "checkpoint_handler = Checkpoint(to_save, DiskSaver(f'{prefix}/models', create_dir=True), n_saved=10, global_step_transform=global_step_from_engine(trainer))\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoint_handler)\n",
    "\n",
    "# Resume Training\n",
    "checkpoint_fp = 'checkpoints/checkpoint.ckpt'\n",
    "if os.path.isfile(checkpoint_fp):\n",
    "    checkpoint = torch.load(checkpoint_fp)\n",
    "    Checkpoint.load_objects(to_load=to_save, checkpoint=checkpoint)\n",
    "\n",
    "# @trainer.on(Events.EPOCH_COMPLETED)\n",
    "# def run_evaluation(engine):\n",
    "#     evaluator.run(val_loader)\n",
    "\n",
    "# @evaluator.on(Events.EPOCH_COMPLETED)\n",
    "# def log_evaluation_results(engine):\n",
    "#     metrics = engine.state.metrics\n",
    "#     avg_usdr = metrics['usdr']\n",
    "#     print(f\"Validation Results - Epoch: {engine.state.epoch} Avg USDR: {avg_usdr:.2f}\")\n",
    "#     tb_logger.writer.add_scalar(\"validation/usdr\", avg_usdr, engine.state.epoch)\n",
    "\n",
    "# Progress Bar\n",
    "pbar = ProgressBar(persist=True)\n",
    "pbar.attach(trainer, metric_names=['running_avg_loss', 'running_avg_usdr'])\n",
    "\n",
    "# Run Training\n",
    "trainer.run(train_loader, max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b47324-65d1-40c1-9e44-daefaaa01642",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c34477a-78c7-42c5-9e8a-1e7af36bd23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device('cuda')\n",
    "m = MSSBandSplitRNN()\n",
    "model.eval()\n",
    "m.bsrnn = model\n",
    "mixture_wav = load_audio(\"mixture.wav\")\n",
    "target_wav = load_audio(\"drums.wav\")\n",
    "with torch.no_grad():\n",
    "    y = m(mixture_wav.cuda())\n",
    "show_idp_audio(mixture_wav)\n",
    "show_idp_audio(y.cpu().detach().numpy())\n",
    "show_idp_audio(target_wav)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf8d3a9-fca6-4926-8443-3fdc73278204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.set_default_device('cuda')\n",
    "import glob\n",
    "models = list(glob.glob(\"*.pt\"))\n",
    "models = sorted(models, key=lambda x: int(x.split(\"-\")[1]))\n",
    "mixture_wav = load_audio(\"mixture.wav\")\n",
    "target_wav = load_audio(\"drums.wav\")\n",
    "print(\"mixture:\")\n",
    "show_idp_audio(mixture_wav)\n",
    "print(\"target:\")\n",
    "show_idp_audio(target_wav)\n",
    "\n",
    "dw = None\n",
    "for i, model_path in enumerate(models):\n",
    "    if i % 5 != 0:\n",
    "        continue\n",
    "    model_bsrnn = torch.load(model_path, map_location=\"cuda\")\n",
    "    m = MSSBandSplitRNN()\n",
    "    m.bsrnn = model_bsrnn\n",
    "    w = torch.cat([t.view(-1) for t in list(m.parameters())])\n",
    "    if dw is None:\n",
    "        dw = nn.L1Loss()(torch.zeros_like(w), w)\n",
    "    else:\n",
    "        dw = nn.L1Loss()(dw, w)\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            y = m(mixture_wav.cuda())\n",
    "        usdr = compute_usdr(y, target_wav.cuda())\n",
    "        print(f\"{model_path} w={dw} usdr={usdr}: \")\n",
    "        \n",
    "        show_idp_audio(y.cpu().detach().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bsrnn]",
   "language": "python",
   "name": "conda-env-bsrnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
